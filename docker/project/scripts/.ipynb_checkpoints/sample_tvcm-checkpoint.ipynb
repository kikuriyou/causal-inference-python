{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スマホゲームのTVCMの効果を推定する\n",
    "- データセット: [岩波データサイエンス Vol.3](https://www.iwanami.co.jp/book/b243764.html)\n",
    "- [森本さん資料](https://dena-analytics.slack.com/archives/C0BD62N21/p1582080304048900()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jp2JLSsmltrH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(123)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "plt.style.use('seaborn-dark')\n",
    "\n",
    "save_dir = 'sample_tvcm'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262582,
     "status": "ok",
     "timestamp": 1580183492030,
     "user": {
      "displayName": "Akira Kikusato",
      "photoUrl": "",
      "userId": "07236968696701566936"
     },
     "user_tz": -540
    },
    "id": "ZEvSHNHEltok",
    "outputId": "8f51964c-f30e-4b77-be9a-1be53ae72dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "End in 0.26s.\n",
      "shape: (10000, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cm_dummy</th>\n",
       "      <th>gamedummy</th>\n",
       "      <th>area_kanto</th>\n",
       "      <th>area_keihan</th>\n",
       "      <th>area_tokai</th>\n",
       "      <th>area_keihanshin</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>marry_dummy</th>\n",
       "      <th>job_dummy1</th>\n",
       "      <th>job_dummy2</th>\n",
       "      <th>job_dummy3</th>\n",
       "      <th>job_dummy4</th>\n",
       "      <th>job_dummy5</th>\n",
       "      <th>job_dummy6</th>\n",
       "      <th>job_dummy7</th>\n",
       "      <th>job_dummy8</th>\n",
       "      <th>inc</th>\n",
       "      <th>pmoney</th>\n",
       "      <th>fam_str_dummy1</th>\n",
       "      <th>fam_str_dummy2</th>\n",
       "      <th>fam_str_dummy3</th>\n",
       "      <th>fam_str_dummy4</th>\n",
       "      <th>fam_str_dummy5</th>\n",
       "      <th>child_dummy</th>\n",
       "      <th>T</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>TVwatch_day</th>\n",
       "      <th>gamesecond</th>\n",
       "      <th>gamecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.427600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.542862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cm_dummy  gamedummy  area_kanto  area_keihan  area_tokai  area_keihanshin  \\\n",
       "0         0          0           0            0           0                1   \n",
       "1         0          0           0            1           0                0   \n",
       "\n",
       "    age  sex  marry_dummy  job_dummy1  job_dummy2  job_dummy3  job_dummy4  \\\n",
       "0  44.5    1            1           1           0           0           0   \n",
       "1  34.5    1            1           1           0           0           0   \n",
       "\n",
       "   job_dummy5  job_dummy6  job_dummy7  job_dummy8    inc  pmoney  \\\n",
       "0           0           0           0           0  249.5     0.0   \n",
       "1           0           0           0           0  800.0    12.5   \n",
       "\n",
       "   fam_str_dummy1  fam_str_dummy2  fam_str_dummy3  fam_str_dummy4  \\\n",
       "0               0               0               1               0   \n",
       "1               0               0               1               0   \n",
       "\n",
       "   fam_str_dummy5  child_dummy  T  F1  F2  F3  M1  M2  M3  TVwatch_day  \\\n",
       "0               0            1  0   0   0   0   0   1   0    33.427600   \n",
       "1               0            1  0   0   0   0   0   1   0    31.542862   \n",
       "\n",
       "   gamesecond  gamecount  \n",
       "0           0          0  \n",
       "1           0          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_url = 'https://raw.githubusercontent.com/iwanami-datascience/vol3/master/kato%26hoshino/q_data_x.csv'\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "df = pd.read_csv(csv_url)\n",
    "print(f'End in {time() - t0 :.2f}s.')\n",
    "\n",
    "print(f'shape: {df.shape}')\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1580183628468,
     "user": {
      "displayName": "Akira Kikusato",
      "photoUrl": "",
      "userId": "07236968696701566936"
     },
     "user_tz": -540
    },
    "id": "2r_S1JANGdkN",
    "outputId": "ef2ffb5e-bc88-4d05-e741-516473e31ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cm_dummy', 'gamedummy', 'area_kanto', 'area_keihan', 'area_tokai',\n",
      "       'area_keihanshin', 'age', 'sex', 'marry_dummy', 'job_dummy1',\n",
      "       'job_dummy2', 'job_dummy3', 'job_dummy4', 'job_dummy5', 'job_dummy6',\n",
      "       'job_dummy7', 'job_dummy8', 'inc', 'pmoney', 'fam_str_dummy1',\n",
      "       'fam_str_dummy2', 'fam_str_dummy3', 'fam_str_dummy4', 'fam_str_dummy5',\n",
      "       'child_dummy', 'T', 'F1', 'F2', 'F3', 'M1', 'M2', 'M3', 'TVwatch_day',\n",
      "       'gamesecond', 'gamecount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk-52WbcMuCX"
   },
   "outputs": [],
   "source": [
    "treat_col = 'cm_dummy'\n",
    "ps_col = 'propensity'\n",
    "outcome_col = 'gamedummy'  # 'gamesecond', 'gamecount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples (treatment): 4144\n",
      "# of samples (control):   5856\n"
     ]
    }
   ],
   "source": [
    "cnt_tr = len(df[df[treat_col]==1])\n",
    "cnt_ct = len(df[df[treat_col]==0])\n",
    "\n",
    "print(f'# of samples (treatment): {cnt_tr}')\n",
    "print(f'# of samples (control):   {cnt_ct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inc, pmoney, age: categorical -> one-hot encoding\n",
    "biased_df = df.copy()\n",
    "cols = ['inc', 'pmoney', 'age']\n",
    "for col in cols:\n",
    "    dummy_df = pd.get_dummies(biased_df[col], prefix=col, drop_first=True)\n",
    "    biased_df = pd.concat([biased_df, dummy_df], axis=1)\n",
    "    biased_df = biased_df.drop(col, axis=1)\n",
    "print(biased_df.columns)\n",
    "biased_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate biased effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_tr = biased_df.loc[biased_df[treat_col]==1, outcome_col].mean()\n",
    "cvr_ct = biased_df.loc[biased_df[treat_col]==0, outcome_col].mean()\n",
    "print('Unadjusted estimation:')\n",
    "print(f'CVR(treatment): {cvr_tr :.6f}')\n",
    "print(f'CVR(control):   {cvr_ct :.6f}')\n",
    "print(f'ATE(biased):    {cvr_tr - cvr_ct :.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate effects with adjusting by propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_inference import EffectEstimatorPS, show_covariate_distribution, sensitivity_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop target-like variables\n",
    "drop_cols = ['cm_dummy', 'gamedummy', 'gamesecond', 'gamecount', 'TVwatch_day']\n",
    "cov_cols = [col for col in biased_df.columns if col not in [treat_col, ps_col, outcome_col] + drop_cols]\n",
    "print(f'# of covariates: {len(cov_cols)}')\n",
    "print(cov_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = biased_df['cm_dummy'].value_counts().min()\n",
    "biased_df = pd.concat([\n",
    "    biased_df[biased_df['cm_dummy']==0].sample(num_sample, random_state=123),\n",
    "    biased_df[biased_df['cm_dummy']==1].sample(num_sample, random_state=123)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution\n",
    "save_file = os.path.join(save_dir, 'covariate_distribution.png')\n",
    "show_covariate_distribution(biased_df, t_col=treat_col, cov_cols=cov_cols, save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = EffectEstimatorPS(t_col=treat_col, cov_cols=cov_cols, ps_col=ps_col)\n",
    "\n",
    "ps_model = LogisticRegression(random_state=123)\n",
    "biased_df[ps_col] = est.estimate_ps(model=ps_model, df=biased_df)\n",
    "\n",
    "save_file = os.path.join(save_dir, 'ps_distribution.png')\n",
    "est.show_ps_distribution(biased_df, title='logistic regression', save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPW\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting\n",
    "est = EffectEstimatorPS(t_col=treat_col, cov_cols=cov_cols, ps_col=ps_col, y_col=outcome_col, \n",
    "                        method='weighting', weighting_method='att', weight_clipping=True, estimand='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate propensity score\n",
    "ps_model = LogisticRegression(random_state=123)\n",
    "#ps_model = CalibratedClassifierCV(LogisticRegression(random_state=123), cv=3, method='isotonic')\n",
    "biased_df[ps_col] = est.estimate_ps(model=ps_model, df=biased_df)\n",
    "\n",
    "est.show_ps_distribution(biased_df, title='logistic regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_df = est.adjust(biased_df)\n",
    "\n",
    "save_file = os.path.join(save_dir, 'covariate_balance_weighting.png')\n",
    "est.show_covariate_balance(unadjusted_df=biased_df, adjusted_df=weighted_df, save_file=save_file)    # , verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.estimate(weighted_df)\n",
    "print(f'\\nATT(weighting): {est.effect_ :.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = EffectEstimatorPS(t_col=treat_col, cov_cols=cov_cols, ps_col=ps_col, y_col=outcome_col, \n",
    "                        method='matching', estimand='average', caliper=0.5)\n",
    "ps_model = LogisticRegression(random_state=123)\n",
    "biased_df[ps_col] = est.estimate_ps(model=ps_model, df=biased_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust confoundedness and check adjusted covariate balance\n",
    "att_matched_df, atc_matched_df = est.adjust(biased_df)\n",
    "\n",
    "save_file = os.path.join(save_dir, 'covariate_balance_matching.png')\n",
    "est.show_covariate_balance(unadjusted_df=biased_df, adjusted_df=att_matched_df, save_file=save_file)  # , verbose=True\n",
    "#est.show_covariate_balance(unadjusted_df=biased_df, adjusted_df=atc_matched_df)  # , verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate effect\n",
    "est.estimate(att_matched_df)\n",
    "att = est.effect_\n",
    "num_treat = est.num_treat_\n",
    "\n",
    "est.estimate(atc_matched_df)\n",
    "atc = est.effect_\n",
    "num_control = est.num_control_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nATE results:')\n",
    "ate = (att * num_treat + atc * num_control) / (num_treat + num_control)\n",
    "print(f'Treatment effect:  {ate: .6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ATT(matching): {att :.6f}')\n",
    "print(f'ATC(matching): {atc :.6f}')\n",
    "print(f'ATE(matching): {ate :.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nfom3s2RJoMb"
   },
   "outputs": [],
   "source": [
    "save_file = os.path.join(save_dir, 'sens_curve.png')\n",
    "sensitivity_analysis(att_matched_df, t_col=treat_col, y_col=outcome_col, save_file=save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hK9W_DJTg2Rq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNN3yKGXj4clYhFXKUJHHcI",
   "collapsed_sections": [],
   "name": "portrait_brave.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
