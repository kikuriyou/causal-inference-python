{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jp2JLSsmltrH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from prep import load_data\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(123)\n",
    "plt.style.use('seaborn-dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262582,
     "status": "ok",
     "timestamp": 1580183492030,
     "user": {
      "displayName": "Akira Kikusato",
      "photoUrl": "",
      "userId": "07236968696701566936"
     },
     "user_tz": -540
    },
    "id": "ZEvSHNHEltok",
    "outputId": "8f51964c-f30e-4b77-be9a-1be53ae72dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "End in 1.40s.\n",
      "Merging dataframes...\n"
     ]
    }
   ],
   "source": [
    "PROJECT = 'npf-brave-220ac3f'\n",
    "input_dir = '../input'\n",
    "pkl_file = os.path.join(input_dir, 'pvp.pkl')\n",
    "rank_pkl_file = os.path.join(input_dir, 'pvp_rank.pkl')\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "df = load_data(PROJECT, pkl_file)\n",
    "rank_df = load_data(PROJECT, rank_pkl_file, is_rank=True)\n",
    "print(f'End in {time() - t0 :.2f}s.')\n",
    "\n",
    "print(\"Merging dataframes...\")\n",
    "t0 = time()\n",
    "df = pd.merge(df, rank_df, how='left', on='appUserId')\n",
    "df = df.fillna(0)\n",
    "del rank_df; gc.collect()\n",
    "print(f'End in {time() - t0 :.2f}s.')\n",
    "\n",
    "print(f'shape: {df.shape}')\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1580183628468,
     "user": {
      "displayName": "Akira Kikusato",
      "photoUrl": "",
      "userId": "07236968696701566936"
     },
     "user_tz": -540
    },
    "id": "2r_S1JANGdkN",
    "outputId": "ef2ffb5e-bc88-4d05-e741-516473e31ef6"
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk-52WbcMuCX"
   },
   "outputs": [],
   "source": [
    "treat_col = 'is_play'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_tr = len(df[df[treat_col]==1])\n",
    "cnt_ct = len(df[df[treat_col]==0])\n",
    "\n",
    "print(f'# of samples (treatment): {cnt_tr}')\n",
    "print(f'# of samples (control):   {cnt_ct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tX2b6_kNJohs"
   },
   "outputs": [],
   "source": [
    "# treatmentごとの各特徴量のヒストグラム(調整前)\n",
    "plt.figure(figsize=(24, 24))\n",
    "tmp1 = df[df[treat_col]==1].sample(1000, random_state=123)\n",
    "tmp0 = df[df[treat_col]==0].sample(2000, random_state=123)\n",
    "vis_cols = [c for c in df.columns if c not in ['appUserId']]\n",
    "for idx, col in enumerate(vis_cols):\n",
    "    plt.subplot(10, 6, idx+1)\n",
    "    plt.hist(tmp1[col], bins=10, alpha=0.5, label='treat')\n",
    "    plt.hist(tmp0[col], bins=10, alpha=0.5, label='control')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "tmp1 = df[(df[treat_col]==1) & (df['prev_grade']>0)].sample(3000, random_state=123)\n",
    "tmp0 = df[(df[treat_col]==0) & (df['prev_grade']>0)].sample(600, random_state=123)\n",
    "print(len(tmp1), len(tmp0))\n",
    "plt.hist(tmp1['prev_grade'], bins=10, alpha=0.5, label='treat')\n",
    "plt.hist(tmp0['prev_grade'], bins=10, alpha=0.5, label='control')\n",
    "plt.legend(loc='best')\n",
    "plt.title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "cols = ['sess_cnt_rank', 'sess_time_total_rank', 'sess_time_min_rank', \n",
    "        'sess_time_mean_rank', 'sess_time_median_rank', 'sess_time_max_rank']\n",
    "sns.pairplot(df[cols].sample(1000, random_state=123))\n",
    "sns.heatmap(df[cols].corr(), annot=True, cmap=\"Reds\", vmax=1, vmin=0, center=0)\n",
    "\n",
    "cols = ['purchase_amt', 'purchase_dates', \n",
    "        'spend_paid_amt', 'spend_paid_dates', 'spend_free_amt', 'spend_free_dates',]\n",
    "sns.pairplot(df[cols].sample(1000, random_state=123))\n",
    "sns.heatmap(df[cols].corr(), annot=True, cmap=\"Reds\", vmax=1, vmin=0, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBA5eK5MJoeM"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "drop_cols = ['appUserId', 'is_ios', 'elapsed_date',   'is_jp', \n",
    "             'sess_cnt', 'sess_time_total', 'sess_time_min', 'sess_time_mean', 'sess_time_median', 'sess_time_max',\n",
    "             'purchase_amt', 'purchase_dates', 'spend_paid_amt', 'spend_paid_dates', 'spend_free_amt', 'spend_free_dates',\n",
    "             'vc_possession', 'unit_possession', \n",
    "             'is_played_sc_0050', 'is_played_sc_0051', 'is_played_sc_0052', 'is_played_sc_0053', \n",
    "             'cnt_sc_0050', 'cnt_sc_0051', 'cnt_sc_0052', 'cnt_sc_0053', \n",
    "             'prev_grade_rank',\n",
    "             # 似た共変量は相関が強いので代表的なものだけ使う\n",
    "             'sess_time_total_rank', 'sess_time_max_rank', \n",
    "             'sess_time_mean_rank', 'sess_time_median_rank', \n",
    "             #'sess_time_min_rank', \n",
    "             #'purchase_amt', 'purchase_dates', \n",
    "             'spend_paid_amt_rank', 'spend_paid_dates_rank', \n",
    "             #'spend_free_amt', 'spend_free_dates',\n",
    "             'cnt_sc_0050_rank', 'cnt_sc_0051_rank', 'cnt_sc_0052_rank', 'cnt_sc_0053_rank', \n",
    "             'is_play', 'pay_amt', 'is_pay', 'event_time']\n",
    "drop_cols.remove(treat_col)\n",
    "use_cols = [c for c in df.columns if c not in drop_cols]\n",
    "print('use_cols: ', use_cols)\n",
    "merged_df = df[use_cols]    # treat_col は含んでいる\n",
    "\n",
    "# 前回プレイユーザーに絞る\n",
    "merged_df = merged_df[merged_df['prev_grade']>0].reset_index(drop=True)\n",
    "\n",
    "#tr_df = merged_df[merged_df[treat_col]==1].reset_index(drop=True)\n",
    "#ct_df = merged_df[merged_df[treat_col]==0].reset_index(drop=True)\n",
    "#merged_df = pd.concat([tr_df, ct_df.sample(n=len(tr_df), random_state=123)]).reset_index(drop=True)\n",
    "#merged_df = pd.concat([tr_df, tr_df, ct_df]).reset_index(drop=True)\n",
    "merged_x = merged_df.drop(treat_col, axis=1).values\n",
    "merged_y = merged_df[treat_col].values\n",
    "\n",
    "train_df, test_df = train_test_split(merged_df, test_size=0.25, random_state=123)\n",
    "train_x = train_df.drop([treat_col], axis=1).values\n",
    "train_y = train_df[treat_col].values\n",
    "test_x = test_df.drop([treat_col], axis=1).values\n",
    "test_y = test_df[treat_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = merged_x\n",
    "y = merged_y\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.Logit(y, X)\n",
    "res = model.fit()\n",
    "\n",
    "print(merged_df.drop(treat_col, axis=1).columns)\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPyJsMZKJobP"
   },
   "outputs": [],
   "source": [
    "print('Start logistic regression....')\n",
    "clf = LogisticRegression(penalty='l1', C=1, solver='saga', random_state=123)\n",
    "clf.fit(train_x, train_y)\n",
    "pred = clf.predict(test_x)\n",
    "auc = roc_auc_score(test_y, pred)\n",
    "print(f'test-AUC(logistic regression): {auc :.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nStart random forest....')\n",
    "clf = RandomForestClassifier(\n",
    "    max_depth=8, \n",
    "    min_samples_leaf=int(len(merged_df)/1000), \n",
    "    n_jobs=-1, random_state=123)\n",
    "clf.fit(train_x, train_y)\n",
    "pred = clf.predict(test_x)\n",
    "auc = roc_auc_score(test_y, pred)\n",
    "print(f'test-AUC(random forest): {auc :.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: scalerやる\n",
    "#scaler = StandardScaler()\n",
    "#merged_x = scaler.fit_transform(merged_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gj8NggfpJoYb"
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', C=0.1, solver='saga', random_state=123)\n",
    "clf.fit(merged_x, merged_y)\n",
    "merged_df['propensity_lr'] = clf.predict_proba(merged_x)[:, 1]\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3Msouy4JoVg"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=8, \n",
    "                             min_samples_leaf=int(len(merged_df)/100), \n",
    "                             n_jobs=-1, random_state=123)\n",
    "clf.fit(merged_x, merged_y)\n",
    "merged_df['propensity_rf'] = clf.predict_proba(merged_x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqWLhdd5JoSk"
   },
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame()\n",
    "drop_cols = [treat_col, 'propensity_lr', 'propensity_rf']\n",
    "use_cols = [c for c in merged_df.columns if c not in drop_cols]\n",
    "importance_df['feature'] = merged_df[use_cols].columns\n",
    "importance_df['importance'] = clf.feature_importances_\n",
    "importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "plt.barh(\n",
    "    importance_df.sort_values(by='importance')['feature'], \n",
    "    importance_df.sort_values(by='importance')['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEDJgnRYJoRc"
   },
   "outputs": [],
   "source": [
    "treat_ps_lr = merged_df.loc[merged_df[treat_col]==1, 'propensity_lr'].values\n",
    "control_ps_lr = merged_df.loc[merged_df[treat_col]==0, 'propensity_lr'].values\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(treat_ps_lr, bins=10, alpha=0.5, label='treat')\n",
    "#plt.hist(control_ps_lr, bins=10, alpha=0.5, label='control')\n",
    "plt.xlim(0, 1)\n",
    "plt.title('logistic regression')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "#plt.hist(treat_ps_lr, bins=10, alpha=0.5, label='treat')\n",
    "plt.hist(control_ps_lr, bins=10, alpha=0.5, label='control')\n",
    "plt.xlim(0, 1)\n",
    "plt.title('logistic regression')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "treat_ps_rf = merged_df.loc[merged_df[treat_col]==1, 'propensity_rf'].values\n",
    "control_ps_rf = merged_df.loc[merged_df[treat_col]==0, 'propensity_rf'].values\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(treat_ps_rf, bins=10, alpha=0.5, label='treat')\n",
    "#plt.hist(control_ps_rf, bins=10, alpha=0.5, label='control')\n",
    "plt.xlim(0, 1)\n",
    "plt.title('random forest')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "#plt.hist(treat_ps_rf, bins=10, alpha=0.5, label='treat')\n",
    "plt.hist(control_ps_rf, bins=10, alpha=0.5, label='control')\n",
    "plt.xlim(0, 1)\n",
    "plt.title('random forest')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVjUX53RJ6N_"
   },
   "source": [
    "# treatment有無での各特徴量のヒストグラム\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "# オリジナル, バイアス有り(unweighted)\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.suptitle('unweighted', fontsize=16)\n",
    "for idx in range(12):\n",
    "    col = f'f{idx}'\n",
    "    plt.subplot(2, 6, idx+1)\n",
    "    plt.hist(treat_df[col], bins=10, alpha=0.5)\n",
    "    plt.hist(control_df[col], bins=10, alpha=0.5)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 傾向スコアの逆数を乗じて補正(IPW)\n",
    "inv_tr_ps = 1 / treat_ps_lr\n",
    "inv_ct_ps = 1 / (1-control_ps_lr)\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.suptitle('IPW', fontsize=16)\n",
    "for idx in range(12):\n",
    "    col = f'f{idx}'\n",
    "    plt.subplot(2, 6, idx+1)\n",
    "    plt.hist(treat_df[col] * inv_tr_ps, bins=10, alpha=0.5)\n",
    "    plt.hist(control_df[col] * inv_ct_ps, bins=10, alpha=0.5)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 傾向スコアの逆数を乗じて補正(IPW, truncated)\n",
    "ps_min, ps_max = 0.05, 0.95\n",
    "inv_tr_ps = 1 / np.clip(treat_ps_lr, ps_min, ps_max)\n",
    "inv_ct_ps = 1 / np.clip(1 - control_ps_lr, ps_min, ps_max)\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.suptitle('IPW, truncated', fontsize=16)\n",
    "for idx in range(12):\n",
    "    col = f'f{idx}'\n",
    "    plt.subplot(2, 6, idx+1)\n",
    "    plt.hist(treat_df[col] * inv_tr_ps, bins=10, alpha=0.5)\n",
    "    plt.hist(control_df[col] * inv_ct_ps, bins=10, alpha=0.5)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 傾向スコアの逆数を乗じて補正(IPW, discarded)\n",
    "is_valid_tr = np.where((treat_ps_lr > ps_min) & (treat_ps_lr < ps_max), 1, 0)\n",
    "is_valid_ct = np.where((1 - control_ps_lr > ps_min) & (1 - control_ps_lr < ps_max), 1, 0)\n",
    "inv_tr_ps = 1 / treat_ps_lr\n",
    "inv_ct_ps = 1 / (1 - control_ps_lr)\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.suptitle('IPW, discarded', fontsize=16)\n",
    "for idx in range(12):\n",
    "    col = f'f{idx}'\n",
    "    plt.subplot(2, 6, idx+1)\n",
    "    plt.hist((treat_df[col] * inv_tr_ps).loc[is_valid_tr == 1], bins=10, alpha=0.5)\n",
    "    plt.hist((control_df[col] * inv_ct_ps).loc[is_valid_ct == 1], bins=10, alpha=0.5)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# overlap weightを加えた傾向スコアの逆数を乗じて補正(overlap weight)\n",
    "inv_tr_ps = np.clip(1 - treat_ps_lr, ps_min, ps_max)\n",
    "inv_ct_ps = np.clip(control_ps_lr, ps_min, ps_max)\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.suptitle('overlap weight', fontsize=16)\n",
    "for idx in range(12):\n",
    "    col = f'f{idx}'\n",
    "    plt.subplot(2, 6, idx+1)\n",
    "    plt.hist(treat_df[col] * inv_tr_ps, bins=10, alpha=0.5)\n",
    "    plt.hist(control_df[col] * inv_ct_ps, bins=10, alpha=0.5)\n",
    "    #sns.distplot(treat_df[col] * inv_tr_ps, kde = True)\n",
    "    #sns.distplot(control_df[col] * inv_ct_ps, kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oK-lvF5cKGCy"
   },
   "source": [
    "# Estimate ATE/ATT/ATC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_col = 'propensity_lr'\n",
    "outcome_col = 'pay_amt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整せず比較した場合\n",
    "cvr_tr = df.loc[df[treat_col]==1, outcome_col].mean()\n",
    "cvr_ct = df.loc[df[treat_col]==0, outcome_col].mean()\n",
    "\n",
    "print('Unadjusted estimation:')\n",
    "print(f'CVR(treatment): {cvr_tr :.6f}')\n",
    "print(f'CVR(control):   {cvr_ct :.6f}')\n",
    "print(f'ATE(biased):    {cvr_tr - cvr_ct :.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rW3qhKKTJ6KY"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://microsoft.github.io/dowhy/_modules/dowhy/causal_estimators/propensity_score_matching_estimator.html\n",
    "\"\"\"\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def matching(df, t_col, y_col, ps_col, caliper=None):\n",
    "    print('Matching....')\n",
    "    t0 = time()\n",
    "    treated = df.loc[df[t_col] == 1].reset_index(drop=True)\n",
    "    control = df.loc[df[t_col] == 0].reset_index(drop=True)\n",
    "\n",
    "    # estimate ATT on treated by summing over difference between matched neighbors\n",
    "    nn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "    control_neighbors = nn.fit(control[ps_col].values.reshape(-1, 1))\n",
    "    distances, indices = control_neighbors.kneighbors(treated[ps_col].values.reshape(-1, 1))\n",
    "\n",
    "    if caliper == None:\n",
    "        caliper = np.median(distances)\n",
    "        print(f'Caliper is setted to the median of distances, caliper = {caliper}')\n",
    "    use_idx = np.where(distances.reshape(-1) <= caliper)\n",
    "    distances = distances[use_idx]\n",
    "    indices = indices[use_idx]\n",
    "    num_treated = len(distances)\n",
    "    #plt.hist(distances, bins=20)\n",
    "    \n",
    "    treated_outcome = treated[y_col].values[use_idx]\n",
    "    control_outcome = control[y_col].values[indices.reshape(-1)]\n",
    "    att = treated_outcome.mean() - control_outcome.mean()\n",
    "    _, pvalue = stats.ttest_ind(treated_outcome, control_outcome, equal_var=False)\n",
    "    \n",
    "    print(f'\\nTreatment outcome: {treated_outcome.mean() :.6f}')\n",
    "    print(f'Control outcome:   {control_outcome.mean() :.6f}')\n",
    "    print(f'ATT(matching):     {att :.6f}, (p-value={pvalue :.6f})')\n",
    "\n",
    "    # prepair dataframes to check SD \n",
    "    print(f'# of matched pairs: {num_treated} ({num_treated / len(treated) :.3f} of all records)')\n",
    "    att_pair_tr_df = pd.DataFrame(treated.values[use_idx])\n",
    "    att_pair_tr_df.columns = [col for col in treated.columns]\n",
    "    att_pair_ct_df = pd.DataFrame(control.values[indices.reshape(-1), :])\n",
    "    att_pair_ct_df.columns = [col for col in control.columns]\n",
    "    \n",
    "    # Now computing ATC\n",
    "    nn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "    treated_neighbors = nn.fit(treated[ps_col].values.reshape(-1, 1))\n",
    "    distances, indices = treated_neighbors.kneighbors(control[ps_col].values.reshape(-1, 1))\n",
    "\n",
    "    use_idx = np.where(distances.reshape(-1) <= caliper)\n",
    "    distances = distances[use_idx]\n",
    "    indices = indices[use_idx]\n",
    "    num_control = len(distances)\n",
    "    \n",
    "    treated_outcome = treated[y_col].values[indices.reshape(-1)]\n",
    "    control_outcome = control[y_col].values[use_idx]\n",
    "    atc = treated_outcome.mean() - control_outcome.mean()\n",
    "    _, pvalue = stats.ttest_ind(treated_outcome, control_outcome, equal_var=False)\n",
    "    \n",
    "    print(f'\\nTreatment outcome: {treated_outcome.mean() :.6f}')\n",
    "    print(f'Control outcome:   {control_outcome.mean() :.6f}')\n",
    "    print(f'ATC(matching):     {atc :.6f}, (p-value={pvalue :.6f})')\n",
    "\n",
    "    # prepair dataframes to check SD \n",
    "    print(f'# of matched pairs: {num_control} ({num_control / len(control) :.3f} of all records)')\n",
    "    atc_pair_tr_df = pd.DataFrame(treated.values[indices.reshape(-1), :])\n",
    "    atc_pair_tr_df.columns = [col for col in treated.columns]\n",
    "    atc_pair_ct_df = pd.DataFrame(control.values[use_idx])\n",
    "    atc_pair_ct_df.columns = [col for col in control.columns]\n",
    "\n",
    "    # Estimate ATE\n",
    "    ate = (att * num_treated + atc * num_control) / (num_treated + num_control)\n",
    "    print(f'\\nATE(matching): {ate :.6f}')\n",
    "\n",
    "    print(f'\\nEnd in {time() - t0 :.2f}s.')\n",
    "\n",
    "    return att_pair_tr_df, att_pair_ct_df, atc_pair_tr_df, atc_pair_ct_df\n",
    "\n",
    "merged_df[outcome_col] = df[outcome_col]\n",
    "att_pair_tr_df, att_pair_ct_df, atc_pair_tr_df, atc_pair_ct_df = matching(\n",
    "    merged_df, t_col=treat_col, y_col=outcome_col, ps_col=ps_col, caliper=1.e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of adjusted covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hi10lzggJ6HW"
   },
   "outputs": [],
   "source": [
    "# standardized difference\n",
    "def absolute_standardized_difference(treat, control):\n",
    "    sd = (treat.mean() - control.mean()) / np.sqrt((treat.var() + control.var()) / 2)\n",
    "    return abs(sd)\n",
    "\n",
    "sd_list = []\n",
    "vis_cols = [c for c in merged_df.columns if c not in [treat_col, outcome_col, 'propensity_lr', 'propensity_rf']]\n",
    "for col in vis_cols:\n",
    "    tr_df = merged_df.loc[merged_df[treat_col]==1, col].reset_index(drop=True)\n",
    "    ct_df = merged_df.loc[merged_df[treat_col]==0, col].reset_index(drop=True)\n",
    "    sd_biased = absolute_standardized_difference(tr_df, ct_df)\n",
    "    sd_adjusted = absolute_standardized_difference(att_pair_tr_df[col], att_pair_ct_df[col])\n",
    "    sd_list.append([sd_biased, sd_adjusted])\n",
    "    print(f'col: {col :<26}, SD(biased): {sd_biased :.6f}, SD(matched): {sd_adjusted :.6f}')\n",
    "\n",
    "sd_arr = np.array(sd_list)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(vis_cols, sd_arr[:, 0], label='biased')\n",
    "plt.scatter(vis_cols, sd_arr[:, 1], label='matched')\n",
    "plt.hlines(y=0.1, xmin=-1, xmax=len(vis_cols), linestyles='dotted', linewidths=0.5)\n",
    "plt.xlim(-0.5, len(vis_cols) - 0.5)\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis\n",
    "- [Sensitivity Analysis without Assumptions, Ding and VanderWeele (2016)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4820664/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evalue_curve(tr, ct):\n",
    "    # risk ratio\n",
    "    rr = tr_est / ct_est if tr_est / ct_est >= 1. else ct_est / tr_est\n",
    "    evalue = rr + np.sqrt(rr * (rr - 1))\n",
    "\n",
    "    print(f'Est. risk ratio: {rr :.4f}')\n",
    "    print(f'E-value:         {evalue :.4f}')\n",
    "\n",
    "    # visualize\n",
    "    x_max = math.ceil(evalue * 3)\n",
    "    y_max = x_max\n",
    "    x_start = rr * (1 - y_max) / (rr - y_max)\n",
    "    x = np.arange(x_start, x_max, 0.02)\n",
    "    y = rr * (1 - x) / (rr - x)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.rcParams[\"font.size\"] = 12\n",
    "    plt.plot(x, y, 'b:', label='boundary')\n",
    "    plt.scatter(evalue, evalue, c='r', label='E-value')\n",
    "    plt.text(evalue * 0.5, evalue * 0.5, 'significant-effect zone',\n",
    "             horizontalalignment='left', verticalalignment='center')\n",
    "    plt.text(evalue * 1.5, evalue * 1.5, 'null-effect zone',\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "    plt.text(evalue, evalue, f'({evalue :.2f}, {evalue :.2f})')\n",
    "    plt.xlim(0, x_max)\n",
    "    plt.ylim(0, y_max)\n",
    "    plt.xlabel('RR(UX)')\n",
    "    plt.ylabel('RR(UY)')\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "print('\\nATT case:')\n",
    "tr_est = att_pair_tr_df[outcome_col].mean()\n",
    "ct_est = att_pair_ct_df[outcome_col].mean()\n",
    "get_evalue_curve(tr_est, ct_est)\n",
    "\n",
    "print('\\nATC case:')\n",
    "tr_est = atc_pair_tr_df[outcome_col].mean()\n",
    "ct_est = atc_pair_ct_df[outcome_col].mean()\n",
    "get_evalue_curve(tr_est, ct_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQy9ChcRKLio"
   },
   "source": [
    "# IPW, Overlap weight\n",
    "**Overlap weight**\n",
    "- https://speakerdeck.com/tomoshige_n/causal-inference-and-data-analysis?slide=37\n",
    "- http://www2.stat.duke.edu/~fl35/OW/MultiTrt_talk.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z269qlEjJ6E_"
   },
   "outputs": [],
   "source": [
    "ps_min, ps_max = 0.01, 0.99\n",
    "#ps_min, ps_max = 0.1, 0.9    # Li et al., 2018\n",
    "tr = merged_df[treat_col].values\n",
    "ps = merged_df[ps_col].values\n",
    "ps = np.clip(ps, ps_min, ps_max)\n",
    "outcome = merged_df[outcome_col].values\n",
    "\n",
    "ipwe0 = ((1 - tr) * outcome / (1 - ps)).sum() / ((1 - tr) / (1 - ps)).sum()\n",
    "ipwe1 = (tr * outcome / ps).sum() / (tr / ps).sum()\n",
    "print(f'ATE(IPW): {ipwe1 - ipwe0 :.6f}')\n",
    "\n",
    "owe0 = ((1 - tr) * outcome * ps).sum() / ((1 - tr) * ps).sum()\n",
    "owe1 = (tr * outcome * (1 - ps)).sum() / (tr * (1 - ps)).sum()\n",
    "print(f'ATE(overlap weight): {owe1 - owe0 :.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSd4_ii1J6Bs"
   },
   "outputs": [],
   "source": [
    "def show_result(arr, cols, adusted_label):\n",
    "    plt.scatter(cols, arr[:, 0], label='biased')\n",
    "    plt.scatter(cols, arr[:, 1], label=adusted_label)\n",
    "    plt.hlines(y=0.1, xmin=-1, xmax=len(vis_cols), linestyles='dotted', linewidths=0.5)\n",
    "    plt.xlim(-0.5, len(vis_cols) - 0.5)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(adusted_label)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "vis_cols = [c for c in merged_df.columns \n",
    "            if c not in [treat_col, outcome_col, 'propensity_lr', 'propensity_rf']]\n",
    "\n",
    "# IPW\n",
    "print('\\nStandardized difference for covariates using IPW')\n",
    "sd_list = []\n",
    "for col in vis_cols:\n",
    "    tr_df = merged_df.loc[merged_df[treat_col]==1, col].reset_index(drop=True)\n",
    "    ct_df = merged_df.loc[merged_df[treat_col]==0, col].reset_index(drop=True)\n",
    "    tr_ps = merged_df.loc[merged_df[treat_col]==1, ps_col].values\n",
    "    ct_ps = merged_df.loc[merged_df[treat_col]==0, ps_col].values\n",
    "    sd_biased = absolute_standardized_difference(tr_df, ct_df)\n",
    "    sd_adjusted = absolute_standardized_difference(tr_df / tr_ps, ct_df / (1 - ct_ps))\n",
    "    sd_list.append([sd_biased, sd_adjusted])\n",
    "    print(f'col: {col :<26}, SD(biased): {sd_biased :.6f}, SD(matched): {sd_adjusted :.6f}')\n",
    "    \n",
    "plt.subplot(2, 2, 1)\n",
    "show_result(np.array(sd_list), vis_cols, 'IPW')\n",
    "\n",
    "# IPW, truncated\n",
    "print('\\nStandardized difference for covariates using truncated IPW')\n",
    "sd_list = []\n",
    "for col in vis_cols:\n",
    "    tr_df = merged_df.loc[merged_df[treat_col]==1, col].reset_index(drop=True)\n",
    "    ct_df = merged_df.loc[merged_df[treat_col]==0, col].reset_index(drop=True)\n",
    "    tr_ps = merged_df.loc[merged_df[treat_col]==1, ps_col].values\n",
    "    ct_ps = merged_df.loc[merged_df[treat_col]==0, ps_col].values\n",
    "    inv_tr_ps = 1 / np.clip(tr_ps, ps_min, ps_max)\n",
    "    inv_ct_ps = 1 / np.clip(1 - ct_ps, ps_min, ps_max)\n",
    "    sd_biased = absolute_standardized_difference(tr_df, ct_df)\n",
    "    sd_adjusted = absolute_standardized_difference(tr_df * inv_tr_ps, ct_df * inv_ct_ps)\n",
    "    sd_list.append([sd_biased, sd_adjusted])\n",
    "    print(f'col: {col :<26}, SD(biased): {sd_biased :.6f}, SD(matched): {sd_adjusted :.6f}')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "show_result(np.array(sd_list), vis_cols, 'IPW, truncated')\n",
    "\n",
    "# IPW, discarded\n",
    "print('\\nStandardized difference for covariates using discarded IPW')\n",
    "sd_list = []\n",
    "for col in vis_cols:\n",
    "    tr_df = merged_df.loc[merged_df[treat_col]==1, col].reset_index(drop=True)\n",
    "    ct_df = merged_df.loc[merged_df[treat_col]==0, col].reset_index(drop=True)\n",
    "    tr_ps = merged_df.loc[merged_df[treat_col]==1, ps_col].values\n",
    "    ct_ps = merged_df.loc[merged_df[treat_col]==0, ps_col].values\n",
    "    is_valid_tr = np.where((tr_ps > ps_min) & (tr_ps < ps_max), 1, 0)\n",
    "    is_valid_ct = np.where((1 - ct_ps > ps_min) & (1 - ct_ps < ps_max), 1, 0)\n",
    "    inv_tr_ps = 1 / tr_ps\n",
    "    inv_ct_ps = 1 / (1 - ct_ps)\n",
    "    sd_biased = absolute_standardized_difference(tr_df, ct_df)\n",
    "    sd_adjusted = absolute_standardized_difference(tr_df * inv_tr_ps, ct_df * inv_ct_ps)\n",
    "    sd_list.append([sd_biased, sd_adjusted])\n",
    "    print(f'col: {col :<26}, SD(biased): {sd_biased :.6f}, SD(matched): {sd_adjusted :.6f}')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "show_result(np.array(sd_list), vis_cols, 'IPW, discarded')\n",
    "\n",
    "# overlap weight\n",
    "print('\\nStandardized difference for covariates using overlap weight')\n",
    "sd_list = []\n",
    "for col in vis_cols:\n",
    "    tr_df = merged_df.loc[merged_df[treat_col]==1, col].reset_index(drop=True)\n",
    "    ct_df = merged_df.loc[merged_df[treat_col]==0, col].reset_index(drop=True)\n",
    "    tr_ps = merged_df.loc[merged_df[treat_col]==1, ps_col].values\n",
    "    ct_ps = merged_df.loc[merged_df[treat_col]==0, ps_col].values\n",
    "    sd_biased = absolute_standardized_difference(tr_df, ct_df)\n",
    "    sd_adjusted = absolute_standardized_difference(tr_df * (1 - tr_ps), ct_df * ct_ps)\n",
    "    sd_list.append([sd_biased, sd_adjusted])\n",
    "    print(f'col: {col :<26}, SD(biased): {sd_biased :.6f}, SD(matched): {sd_adjusted :.6f}')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "show_result(np.array(sd_list), vis_cols, 'overlap weight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzD1n6PiJ59s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nfom3s2RJoMb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "to9kuODIJoJV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FJF94bgJoGR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCPvWKEhJn-6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hK9W_DJTg2Rq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNN3yKGXj4clYhFXKUJHHcI",
   "collapsed_sections": [],
   "name": "portrait_brave.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
